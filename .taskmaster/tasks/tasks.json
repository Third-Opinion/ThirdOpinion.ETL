{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Analyze existing table schemas and relationships",
        "description": "Review all DDL files in ddl_exports/ to understand table structures, relationships, and data patterns for the 8 required FHIR entities",
        "details": "Use the Read tool to examine key DDL files for care_plans, conditions, diagnostic_reports, document_references, medication_requests, observations, practitioners, and procedures. Document primary keys, foreign keys, and relationship patterns. Map out the normalized table structure for each entity to understand how to join tables in materialized views. Create a comprehensive data dictionary showing table relationships and key fields needed for fact views.",
        "testStrategy": "Validate table relationships by running test queries against each entity's tables. Confirm primary/foreign key relationships and identify any missing tables or unexpected schema variations.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Review DDL export directory structure",
            "description": "Examine the ddl_exports/ directory to understand what table schemas are available",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1
          },
          {
            "id": 2,
            "title": "Analyze FHIR entity table schemas",
            "description": "Review table definitions for the 8 FHIR entities: care_plans, conditions, diagnostic_reports, document_references, medication_requests, observations, practitioners, procedures",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1
          },
          {
            "id": 3,
            "title": "Identify foreign key relationships and dependencies",
            "description": "Map out how the FHIR entities relate to each other through foreign keys and reference tables",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1
          },
          {
            "id": 4,
            "title": "Document data patterns from existing views",
            "description": "Study the existing fact_fhir_patients_view_v1 and fact_fhir_encounters_view_v1 to understand naming conventions, JSON aggregation patterns, and materialized view structure",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1
          },
          {
            "id": 5,
            "title": "Create schema analysis summary document",
            "description": "Compile findings into a comprehensive analysis document that will guide implementation of the remaining materialized views",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1
          }
        ]
      },
      {
        "id": 2,
        "title": "Create fact_fhir_care_plans_view_v1 materialized view",
        "description": "Implement materialized view for care plans entity following PRD specifications with scheduled refresh pattern",
        "details": "Create materialized view joining care_plans table with care_plan_categories, care_plan_goals, care_plan_identifiers, and care_plan_care_teams. Use JSON_PARSE and LISTAGG for aggregating related data. Include REGEXP_REPLACE for data sanitization. Remove AUTO REFRESH and implement for scheduled refresh. Include all core care plan fields, aggregated categories, goals, and care team information as JSON structures using SUPER data type.",
        "testStrategy": "Verify view creates successfully, test query performance, validate JSON structure output, and confirm data integrity through row count comparisons with source tables.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design care plans view structure and schema",
            "description": "Analyze existing patient/encounter view patterns and design the structure for fact_fhir_care_plans_view_v1",
            "dependencies": [],
            "details": "Review existing fact_fhir_patients_view_v1 and fact_fhir_encounters_view_v1 to understand JSON aggregation patterns. Design the view schema including core care_plans fields, aggregated categories, goals, identifiers, and care team information. Define the SUPER data type structure for JSON fields and establish the overall view architecture.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement core table joins for care plans entity",
            "description": "Create the base SQL joins between care_plans and its related tables",
            "dependencies": [
              "2.1"
            ],
            "details": "Implement LEFT JOINs from care_plans table to care_plan_categories, care_plan_goals, care_plan_identifiers, and care_plan_care_teams. Establish proper join conditions and ensure all related data is captured. Include any necessary filtering for active records and proper data relationships.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Develop JSON aggregation logic using JSON_PARSE and LISTAGG",
            "description": "Implement the JSON aggregation patterns for categories, goals, and care team data",
            "dependencies": [
              "2.2"
            ],
            "details": "Use JSON_PARSE and LISTAGG following established patterns from existing views to aggregate care_plan_categories, care_plan_goals, and care_plan_care_teams into JSON structures. Implement proper grouping and ensure SUPER data type compatibility for the aggregated JSON fields.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Create materialized view with data sanitization and performance testing",
            "description": "Complete the view creation with REGEXP_REPLACE sanitization and validate performance",
            "dependencies": [
              "2.3"
            ],
            "details": "Create the final materialized view with REGEXP_REPLACE for data sanitization. Remove AUTO REFRESH configuration for scheduled refresh pattern. Test query performance, validate JSON structure output, and perform data integrity checks through row count comparisons with source tables. Ensure the view follows the established naming convention and performance standards.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 3,
        "title": "Create fact_fhir_conditions_view_v1 materialized view",
        "description": "Implement materialized view for conditions entity with comprehensive condition data aggregation",
        "details": "Create materialized view joining conditions table with condition_body_sites, condition_categories, condition_codes, condition_evidence, condition_extensions, condition_notes, and condition_stages. Aggregate condition codes, body sites, and clinical status information. Use LISTAGG for multiple values and JSON_PARSE for complex nested structures. Include onset/abatement dates, clinical status, verification status, and all coded elements.",
        "testStrategy": "Test view creation, validate condition code aggregation, verify clinical status handling, and ensure proper null handling for optional condition attributes.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze conditions table schema and relationships",
            "description": "Thoroughly examine the conditions main table structure (40+ columns) and map relationships with 7 related tables",
            "dependencies": [],
            "details": "Review the conditions table schema focusing on key columns like clinical_status, verification_status, onset/abatement dates, and severity. Document relationships with condition_body_sites, condition_categories, condition_codes, condition_evidence, condition_extensions, condition_notes, and condition_stages tables. Identify primary/foreign key relationships, cardinality, and data types. Create a comprehensive mapping document showing how data flows between tables and which columns will be needed for the materialized view.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Design view structure following existing patterns",
            "description": "Create the view structure based on existing fact_fhir patterns from encounters and patients views",
            "dependencies": [
              "3.1"
            ],
            "details": "Study fact_fhir_encounters_view_v1 and fact_fhir_patients_view_v1 to understand the established patterns for column naming, data aggregation, and JSON structure. Design the fact_fhir_conditions_view_v1 structure with appropriate column selection from the main conditions table. Plan the JOIN strategy for all 7 related tables, determining LEFT vs INNER joins based on data requirements. Define the output columns including aggregated fields for codes, body sites, categories, and evidence.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement JSON aggregations for condition categories and codes",
            "description": "Develop complex JSON aggregation logic for multiple condition-related data points using LISTAGG and JSON_PARSE",
            "dependencies": [
              "3.2"
            ],
            "details": "Implement LISTAGG aggregations for condition_codes (including system, code, display), condition_body_sites, condition_categories, and condition_evidence. Use JSON_PARSE for nested structures like clinical_status, verification_status, and onset/abatement complex types. Create proper GROUP BY clauses and handle NULL values appropriately. Ensure JSON output is properly formatted and follows the same patterns as other views. Handle multiple codes per condition and proper concatenation with appropriate delimiters.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Add data quality checks and sanitization",
            "description": "Implement comprehensive data validation and sanitization logic for complex condition hierarchies",
            "dependencies": [
              "3.3"
            ],
            "details": "Add NULL handling for all optional attributes including onset/abatement dates, severity, and stage information. Implement data type conversions where necessary, especially for date fields and coded elements. Add validation for clinical_status and verification_status values against FHIR specifications. Create sanitization logic for text fields in notes and evidence descriptions. Ensure proper handling of edge cases like conditions without codes or body sites. Add CASE statements for conditional logic where needed.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Test and validate the view",
            "description": "Execute comprehensive testing of the materialized view including data accuracy and performance",
            "dependencies": [
              "3.4"
            ],
            "details": "Create and execute the CREATE MATERIALIZED VIEW statement in Redshift. Run validation queries to verify condition code aggregation is working correctly. Test clinical status and verification status handling with various data scenarios. Validate proper NULL handling for optional condition attributes. Check JSON aggregation output for correctness and proper formatting. Compare row counts between source tables and view results. Test performance with sample queries and verify indexes are properly utilized. Document any data quality issues or anomalies found during testing.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 4,
        "title": "Create fact_fhir_diagnostic_reports_view_v1 materialized view",
        "description": "Implement materialized view for diagnostic reports with results and performer aggregation",
        "details": "Create materialized view joining diagnostic_reports with diagnostic_report_results, diagnostic_report_performers, diagnostic_report_categories, diagnostic_report_media, diagnostic_report_presented_forms, and diagnostic_report_based_on. Aggregate results as JSON array, include performer information, and handle media attachments. Use JSON_PARSE for structured data and LISTAGG for lists. Include status, issued date, effective period, and all coded categories.",
        "testStrategy": "Validate view creation, test results aggregation accuracy, verify performer data integrity, and confirm proper handling of media and presented forms.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze diagnostic_reports schema and related tables",
            "description": "Study the diagnostic_reports table structure and all 6 related tables to understand data relationships and aggregation requirements",
            "dependencies": [],
            "details": "Examine diagnostic_reports base table schema including columns, data types, and constraints. Analyze related tables: diagnostic_report_results (result values and references), diagnostic_report_performers (practitioner/organization references), diagnostic_report_categories (category codings), diagnostic_report_media (attachments and images), diagnostic_report_presented_forms (report documents), and diagnostic_report_based_on (source orders/requests). Document foreign key relationships, cardinality, and identify required aggregation patterns for each related table.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Design view structure with result and performer aggregations",
            "description": "Create the view design following existing patterns, defining column structure and aggregation strategies for results and performers",
            "dependencies": [
              "4.1"
            ],
            "details": "Design view columns including: diagnostic_report_id, status, issued_date, effective_period_start/end, conclusion text, and aggregated fields. Plan JSON structure for results array containing observation references, values, and interpretation codes. Design performer aggregation to include practitioner/organization details with roles. Define category aggregation strategy using LISTAGG. Structure media and presented_forms handling with proper null checks. Document column naming conventions consistent with existing views.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement core view with JSON aggregations",
            "description": "Write the SQL for the materialized view implementing JSON_PARSE for results and categories with proper joins",
            "dependencies": [
              "4.2"
            ],
            "details": "Implement CREATE MATERIALIZED VIEW statement with base diagnostic_reports table. Add LEFT JOINs for all 6 related tables using appropriate foreign keys. Implement JSON_PARSE aggregation for results array including observation_reference, value_quantity, value_codeable_concept, and interpretation. Create performer JSON aggregation with practitioner/organization references and display names. Use LISTAGG for categories with proper delimiters. Implement media attachment handling with content_type and url fields. Add presented_forms aggregation for report documents.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Add data sanitization and performance optimizations",
            "description": "Implement data cleaning, null handling, and performance optimizations following established patterns",
            "dependencies": [
              "4.3"
            ],
            "details": "Add TRIM and NULLIF functions for text fields to handle empty strings and whitespace. Implement proper NULL handling for all aggregated fields using COALESCE. Add WHERE clauses to filter out invalid or test data if needed. Create appropriate indexes on foreign key columns in source tables. Add SORTKEY and DISTKEY specifications for optimal query performance. Implement date formatting consistency for issued_date and effective_period fields. Add proper error handling for JSON_PARSE operations.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Test view with sample data and validate aggregations",
            "description": "Execute comprehensive tests to verify view functionality, data accuracy, and performance",
            "dependencies": [
              "4.4"
            ],
            "details": "Create test queries to validate view creation without errors. Test results aggregation by comparing JSON array contents with source diagnostic_report_results records. Verify performer information completeness and accuracy against diagnostic_report_performers. Validate category aggregation using sample reports with multiple categories. Test media and presented_forms handling including null cases. Measure query performance with different data volumes. Verify all status values are properly represented. Test edge cases like reports without results or performers.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 5,
        "title": "Create fact_fhir_document_references_view_v1 materialized view",
        "description": "Implement materialized view for document references with content and author aggregation",
        "details": "Create materialized view joining document_references with document_reference_content, document_reference_authors, document_reference_categories, and document_reference_identifiers. Aggregate content metadata, author information, and categories. Include document status, creation date, document type, and security labels. Use JSON_PARSE for content structure and LISTAGG for multiple authors and categories.",
        "testStrategy": "Test view creation, validate content aggregation, verify author data completeness, and ensure proper handling of document security metadata.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze document_references schema and related tables",
            "description": "Examine the structure of document_references table and its 4 related tables (document_reference_content, document_reference_authors, document_reference_categories, document_reference_identifiers) to understand relationships and data types",
            "dependencies": [],
            "details": "Review the document_references base table schema including primary keys, foreign keys, and data types. Analyze document_reference_content for content metadata structure, document_reference_authors for author information fields, document_reference_categories for category classification, and document_reference_identifiers for identifier types. Document the cardinality relationships (one-to-many) between base table and related tables. Identify fields needed for aggregation including document status, creation date, document type, and security labels.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Design view structure with joins and aggregation strategy",
            "description": "Design the materialized view structure incorporating all necessary joins with the 4 related tables and plan the aggregation approach for content and author data",
            "dependencies": [
              "5.1"
            ],
            "details": "Create the view design with LEFT OUTER JOINs from document_references to document_reference_content, document_reference_authors, document_reference_categories, and document_reference_identifiers. Plan LISTAGG strategy for multiple authors and categories with appropriate delimiters. Design JSON structure for content metadata aggregation. Define the column selection including document_reference_id as primary key, document status, creation date, document type, security labels, and aggregated fields. Ensure consistency with existing view patterns from fact_fhir_patients_view_v1 and fact_fhir_encounters_view_v1.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement JSON aggregations and LISTAGG functions",
            "description": "Develop the JSON_PARSE implementations for content structure and LISTAGG functions for author and category aggregations following established patterns",
            "dependencies": [
              "5.2"
            ],
            "details": "Implement JSON_PARSE for document_reference_content to extract and structure content metadata as JSON objects. Create LISTAGG expressions for document_reference_authors to concatenate multiple authors with appropriate formatting (e.g., author names, roles). Implement LISTAGG for document_reference_categories to aggregate category codes and display values. Handle NULL values and empty aggregations gracefully. Apply GROUP BY clause correctly for all non-aggregated columns. Ensure proper handling of security metadata fields including confidentiality levels and access restrictions.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Test view creation and validate data integrity",
            "description": "Execute the materialized view creation, test content structure validation, and verify completeness of author and security metadata",
            "dependencies": [
              "5.3"
            ],
            "details": "Execute CREATE MATERIALIZED VIEW statement in Redshift and verify successful creation. Test with sample queries to validate content aggregation produces valid JSON structures. Verify author data completeness by checking LISTAGG results include all authors per document. Test category aggregation for documents with multiple categories. Validate security metadata handling including proper representation of confidentiality levels and security labels. Check for performance with appropriate DISTKEY and SORTKEY selection. Verify handling of edge cases such as documents without authors, content, or categories. Document any data quality issues or missing relationships.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 6,
        "title": "Create fact_fhir_medication_requests_view_v1 materialized view",
        "description": "Implement materialized view for medication requests with dosage and category aggregation",
        "details": "Create materialized view joining medication_requests with medication_request_dosage_instructions, medication_request_categories, medication_request_notes, and medication_request_identifiers. Join with medications table for medication details. Aggregate dosage instructions as JSON, include prescriber information, fulfillment status, and categories. Handle dispense requests, substitution preferences, and prior authorizations.",
        "testStrategy": "Validate view creation, test dosage instruction aggregation, verify medication data joins correctly, and confirm proper handling of prescription workflow statuses.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze medication_requests schema and related tables",
            "description": "Examine medication_requests table structure and all related tables including medication_request_dosage_instructions, medication_request_categories, medication_request_notes, medication_request_identifiers, and medications table",
            "dependencies": [],
            "details": "Document table schemas, identify primary/foreign keys, analyze data types and relationships. Review existing medication_requests data to understand dosage instruction patterns, timing complexities, and prescription workflow states. Examine medications table structure for medication details integration. Document any data quality issues or missing relationships that need handling.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Design view structure with complex joins and aggregations",
            "description": "Create the SQL design for joining medication_requests with 5 related tables and define aggregation strategy for dosage instructions",
            "dependencies": [
              "6.1"
            ],
            "details": "Design LEFT JOINs for medication_request_dosage_instructions, medication_request_categories, medication_request_notes, medication_request_identifiers, and medications tables. Plan JSON aggregation structure for complex dosage instructions including timing patterns, quantity, and frequency. Define grouping strategy and handle one-to-many relationships. Include prescriber information fields, fulfillment status tracking, and category aggregation logic.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement JSON aggregation for dosage instructions",
            "description": "Develop complex JSON aggregation logic for dosage instructions with timing patterns, quantities, and administration routes",
            "dependencies": [
              "6.2"
            ],
            "details": "Implement JSON_PARSE and JSON_STRINGIFY for dosage instruction objects. Create nested JSON structures for timing patterns (daily, weekly, PRN), dosage quantities, routes of administration, and duration. Use LISTAGG with proper delimiters for multiple dosage instructions per medication request. Handle special cases like tapered doses, split doses, and complex timing schedules. Ensure proper null handling and data type conversions.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Add prescription workflow and authorization handling",
            "description": "Implement dispense request processing, substitution preferences, prior authorization logic, and prescription workflow status tracking",
            "dependencies": [
              "6.3"
            ],
            "details": "Add columns for dispense_request details including quantity, expected supply duration, and number of refills. Implement substitution_allowed flag and substitution reason handling. Create logic for prior_authorization status and authorization numbers. Track prescription workflow states (active, completed, cancelled, entered-in-error, draft). Include fulfillment status tracking and last dispensed date calculations. Handle special authorization requirements and controlled substance indicators.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Test dosage accuracy and prescription workflow logic",
            "description": "Validate dosage instruction aggregation accuracy, prescription workflow state transitions, and overall view performance",
            "dependencies": [
              "6.4"
            ],
            "details": "Create test cases for complex dosage patterns including PRN medications, tapered doses, and multiple daily administrations. Validate JSON aggregation produces valid, parseable structures. Test prescription workflow state transitions and prior authorization handling. Verify medication details from medications table join correctly. Test performance with large datasets and optimize if needed. Validate edge cases like missing dosage instructions, null prescriber information, and incomplete fulfillment data.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 7,
        "title": "Create fact_fhir_observations_view_v1 materialized view",
        "description": "Implement materialized view for observations with components and reference ranges using enhanced aggregation patterns",
        "details": "Create materialized view joining observations with observation_components, observation_categories, observation_performers, observation_reference_ranges, observation_interpretations, observation_notes, observation_derived_from, and observation_members. Use MAX/MIN for vital signs pivoting as shown in PRD example. Aggregate components as JSON, include reference ranges, and handle observation relationships. Implement the blood pressure systolic/diastolic pattern from PRD specifications.",
        "testStrategy": "Test view creation, validate vital signs pivoting logic, verify component aggregation accuracy, and ensure reference ranges are properly associated with observations.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze observations and 8 related tables structure",
            "description": "Perform comprehensive analysis of the observations main table (44 columns) and all 8 related tables to understand data relationships and aggregation requirements",
            "dependencies": [],
            "details": "Analyze observations table structure including all 44 columns. Document relationships with observation_components, observation_categories, observation_performers, observation_reference_ranges, observation_interpretations, observation_notes, observation_derived_from, and observation_members tables. Identify primary and foreign keys, data types, and cardinality of relationships. Review existing data patterns for vital signs, especially blood pressure measurements with systolic/diastolic components.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Design view with MAX/MIN vital signs pivoting logic",
            "description": "Design the materialized view structure implementing MAX/MIN functions for vital signs pivoting as specified in PRD, particularly for blood pressure patterns",
            "dependencies": [
              "7.1"
            ],
            "details": "Design SQL structure for vital signs pivoting using MAX(CASE WHEN component_code = 'systolic' THEN value END) and MIN(CASE WHEN component_code = 'diastolic' THEN value END) patterns. Define the main SELECT statement structure with proper GROUP BY clauses. Plan the pivoting logic for common vital signs: blood pressure (systolic/diastolic), temperature, pulse, respiratory rate, and oxygen saturation. Ensure the design accommodates both single-value and multi-component observations.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement component JSON aggregations",
            "description": "Develop JSON aggregation logic for observation components including value, unit, and interpretation data",
            "dependencies": [
              "7.2"
            ],
            "details": "Implement JSON_ARRAYAGG or similar functions to aggregate observation_components data into structured JSON arrays. Each component should include: code, display, value, unit, interpretation, and reference range. Handle numeric, string, and coded value types. Ensure proper NULL handling and data type conversions. Create nested JSON structures that preserve component relationships and ordering.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Add reference ranges and interpretations aggregation",
            "description": "Implement aggregation logic for reference ranges and interpretations, ensuring proper association with observations and components",
            "dependencies": [
              "7.3"
            ],
            "details": "Join observation_reference_ranges table and aggregate reference range data (low, high, normal range text) as JSON. Include observation_interpretations data with proper code mappings (H, L, N, etc.). Ensure reference ranges are correctly associated with specific components when applicable. Handle age-specific and context-specific reference ranges. Aggregate interpretation codes and display text using LISTAGG or JSON functions.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Handle observation relationships and complete view",
            "description": "Implement observation relationship handling for derived_from and members tables, and finalize the complete materialized view",
            "dependencies": [
              "7.4"
            ],
            "details": "Join observation_derived_from to track parent-child observation relationships. Handle observation_members for panel/battery observations. Implement proper aggregation for observation_performers, observation_categories, and observation_notes. Add all remaining columns including status, effective dates, issued date, and method. Ensure proper NULL handling for optional relationships. Complete the CREATE MATERIALIZED VIEW statement with all joins and aggregations.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Test vital signs pivoting and component aggregation",
            "description": "Thoroughly test the materialized view focusing on vital signs pivoting accuracy and component aggregation integrity",
            "dependencies": [
              "7.5"
            ],
            "details": "Create test queries to validate blood pressure systolic/diastolic pivoting returns correct MAX/MIN values. Test component JSON aggregation for multi-component observations (CBC panels, metabolic panels). Verify reference ranges are properly associated with observations and components. Test observation relationship tracking (derived_from, members). Validate performance with sample data and ensure no data loss during aggregation. Document any edge cases or data quality issues discovered during testing.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 8,
        "title": "Create fact_fhir_practitioners_view_v1 materialized view",
        "description": "Implement materialized view for practitioners with names, addresses, and telecom aggregation",
        "details": "Create materialized view joining practitioners with practitioner_names, practitioner_addresses, and practitioner_telecoms. Use similar name ranking logic as in existing patient view. Aggregate addresses and contact information. Include practitioner qualifications, specialties, and active status. Use JSON_PARSE for structured contact data and address information.",
        "testStrategy": "Test view creation, validate name ranking logic consistency with patient view, verify address and telecom aggregation, and confirm practitioner qualification data integrity.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze practitioner table structure and existing view patterns",
            "description": "Study the practitioner-related tables (practitioners, practitioner_names, practitioner_addresses, practitioner_telecoms) and review the existing patient view implementation to understand the name ranking logic that needs to be reused",
            "dependencies": [],
            "details": "Examine the schema and relationships of all practitioner tables. Document the structure of practitioner_names, practitioner_addresses, and practitioner_telecoms tables. Review fact_fhir_patients_view_v1 to understand the name ranking logic implementation that should be adapted. Identify practitioner-specific fields like qualifications, specialties, and active status. Document the JSON_PARSE patterns used in existing views for structured contact data.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement practitioner view with name ranking and aggregations",
            "description": "Create the fact_fhir_practitioners_view_v1 materialized view by joining practitioner tables and implementing name ranking logic adapted from the patient view, including address and telecom aggregations",
            "dependencies": [
              "8.1"
            ],
            "details": "Write the CREATE MATERIALIZED VIEW statement joining practitioners with practitioner_names using adapted name ranking logic from patient view. Implement LEFT JOINs with practitioner_addresses and practitioner_telecoms tables. Use JSON_PARSE for structured contact data and address information following established patterns. Apply LISTAGG for aggregating multiple addresses and telecom entries. Include practitioner-specific fields: qualifications, specialties, and active status. Ensure proper NULL handling and data type conversions.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Test and validate practitioner view implementation",
            "description": "Execute comprehensive testing of the fact_fhir_practitioners_view_v1 to ensure name ranking consistency with patient view and validate all aggregations work correctly",
            "dependencies": [
              "8.2"
            ],
            "details": "Create and execute the materialized view in the database. Test name ranking logic by comparing results with similar patterns in patient view for consistency. Validate address aggregation produces correct JSON structures. Verify telecom aggregation handles multiple contact methods properly. Test edge cases: practitioners with no names, multiple addresses, or missing telecom data. Confirm practitioner qualifications and specialties are correctly included. Document query performance metrics and any optimization opportunities.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 9,
        "title": "Create fact_fhir_procedures_view_v1 materialized view",
        "description": "Implement materialized view for procedures with code codings and identifier aggregation",
        "details": "Create materialized view joining procedures with procedure_code_codings and procedure_identifiers. Aggregate procedure codes, include performer information, procedure dates, and status. Handle procedure relationships, outcomes, and complications. Use JSON_PARSE for coded elements and LISTAGG for multiple code codings per procedure.",
        "testStrategy": "Test view creation, validate procedure code aggregation, verify date handling for performed procedures, and ensure proper status and outcome tracking.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze procedures table structure and related tables",
            "description": "Examine the procedures base table and its two related tables (procedure_code_codings and procedure_identifiers) to understand data structure, relationships, and aggregation requirements",
            "dependencies": [],
            "details": "Review procedures table schema including performer fields, status columns, date fields (performed_period_start, performed_period_end), and outcome columns. Analyze procedure_code_codings table structure for code aggregation using LISTAGG. Examine procedure_identifiers table for identifier aggregation patterns. Document any JSON fields that need JSON_PARSE treatment. Identify relationships with other entities like encounters or patients.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Design view structure with code and identifier aggregations",
            "description": "Create the SQL design for fact_fhir_procedures_view_v1 with proper joins and aggregation logic for procedure codes and identifiers",
            "dependencies": [
              "9.1"
            ],
            "details": "Design LEFT JOINs from procedures to procedure_code_codings and procedure_identifiers. Define LISTAGG aggregation for procedure codes with proper delimiters and ordering. Structure identifier aggregation similar to other views. Plan JSON_PARSE usage for coded elements like status_reason or outcome. Include all required fields: procedure dates, performer information, status, outcomes, and complications. Define proper GROUP BY clauses for aggregations.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement materialized view with performer and outcome handling",
            "description": "Write and execute the CREATE MATERIALIZED VIEW statement with complete aggregations, performer information extraction, and outcome/complication tracking",
            "dependencies": [
              "9.2"
            ],
            "details": "Implement the full SQL for fact_fhir_procedures_view_v1. Use LISTAGG(DISTINCT ...) for procedure code aggregations from procedure_code_codings. Apply JSON_PARSE where needed for structured fields. Extract performer information (could be practitioner references or inline data). Handle procedure dates properly (performed_period_start/end). Include status tracking and outcome/complication fields. Ensure proper NULL handling in aggregations. Add appropriate column aliases for clarity.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Test view creation and validate aggregations",
            "description": "Execute comprehensive tests to verify the materialized view works correctly, focusing on code aggregation accuracy and data completeness",
            "dependencies": [
              "9.3"
            ],
            "details": "Test materialized view creation and refresh. Validate LISTAGG aggregation produces correct procedure code lists without duplicates. Verify procedures with multiple code_codings aggregate properly. Test procedures with no related codes or identifiers (NULL handling). Validate performer information extraction and date field population. Compare row counts between base table and view. Test a sample of procedures to ensure status, outcomes, and complications are captured correctly. Document any performance considerations for the aggregations.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 10,
        "title": "Upgrade existing views to V2 and implement scheduled refresh infrastructure",
        "description": "Convert existing patient and encounter views to V2 with enhanced features, remove AUTO REFRESH, and set up scheduled refresh system",
        "details": "Update fact_fhir_patients_view_v1.sql to V2 with window functions, LISTAGG, and subqueries as specified in PRD appendix. Update fact_fhir_encounters_view_v1.sql to V2 with duration calculations, participant aggregations, and diagnosis/procedure counts. Remove AUTO REFRESH from all views. Create AWS Lambda function for scheduled refresh, implement CloudWatch Events rule for hourly execution, and create deployment scripts with AWS CLI commands for all 10 materialized views.",
        "testStrategy": "Test V2 view functionality with window functions, validate scheduled refresh execution, verify Lambda function operation, confirm CloudWatch Events scheduling, and run end-to-end deployment validation script to ensure all views refresh successfully.",
        "priority": "high",
        "dependencies": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze PRD V2 specifications for enhanced view features",
            "description": "Review PRD appendix for V2 requirements including window functions, LISTAGG usage, and subquery patterns for patients and encounters views",
            "dependencies": [],
            "details": "Examine PRD specifications for fact_fhir_patients_view_v2 requirements including window functions for patient ranking, LISTAGG for aggregating identifiers and addresses, and subquery patterns for related data. Review fact_fhir_encounters_view_v2 requirements for duration calculations, participant aggregations, diagnosis/procedure counts. Document all new fields, aggregation logic, and performance considerations. Create implementation checklist for each view upgrade.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Upgrade fact_fhir_patients_view_v1 to V2 with enhanced features",
            "description": "Implement V2 version of patients view with window functions, LISTAGG aggregations, and complex subqueries as specified in PRD",
            "dependencies": [
              "10.1"
            ],
            "details": "Modify fact_fhir_patients_view_v1.sql to create V2 version. Add window functions for patient ranking by last updated timestamp, implement LISTAGG for concatenating multiple identifiers and addresses into single fields, create subqueries for counting related resources (encounters, conditions, observations). Add new calculated fields like age_at_last_encounter, total_encounter_count, active_condition_count. Ensure proper NULL handling and data type conversions for SUPER fields.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Upgrade fact_fhir_encounters_view_v1 to V2 with duration calculations",
            "description": "Implement V2 version of encounters view with duration calculations, participant aggregations, and diagnosis/procedure counts",
            "dependencies": [
              "10.1"
            ],
            "details": "Modify fact_fhir_encounters_view_v1.sql to create V2 version. Add duration calculation using DATEDIFF between period_start and period_end, implement participant aggregation using LISTAGG to combine all participants into JSON array, add diagnosis and procedure counts using subqueries. Include new fields for length_of_stay, participant_count, primary_diagnosis, and procedure_list. Implement proper handling of emergency vs scheduled encounters.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Remove AUTO REFRESH from all 10 materialized views",
            "description": "Update all existing materialized view definitions to remove AUTO REFRESH YES clause in preparation for scheduled refresh",
            "dependencies": [
              "10.2",
              "10.3"
            ],
            "details": "Modify all 10 materialized view SQL files to remove AUTO REFRESH YES clause: fact_fhir_patients_view, fact_fhir_encounters_view, fact_fhir_care_plans_view, fact_fhir_conditions_view, fact_fhir_diagnostic_reports_view, fact_fhir_document_references_view, fact_fhir_medication_requests_view, fact_fhir_observations_view, fact_fhir_practitioners_view, fact_fhir_procedures_view. Replace with NO AUTO REFRESH or omit the clause entirely. Document the change in each file header.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Design and implement AWS Lambda function for scheduled refresh",
            "description": "Create Lambda function to execute REFRESH MATERIALIZED VIEW commands for all 10 views with error handling and logging",
            "dependencies": [
              "10.4"
            ],
            "details": "Create Python Lambda function using boto3 to connect to Redshift via Data API. Implement refresh logic for all 10 materialized views in sequence with proper error handling and retry logic. Add CloudWatch logging for each refresh operation including start time, completion time, and row counts. Include configuration for Redshift cluster identifier, database name, and IAM role. Implement timeout handling and notification on failures via SNS.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Configure CloudWatch Events rule and IAM permissions",
            "description": "Set up CloudWatch Events rule for hourly execution and configure IAM roles with necessary permissions",
            "dependencies": [
              "10.5"
            ],
            "details": "Create CloudWatch Events rule with cron expression for hourly execution (0 * * * ? *). Configure IAM role for Lambda with permissions for redshift-data:ExecuteStatement, redshift-data:DescribeStatement, redshift-data:GetStatementResult, logs:CreateLogGroup, logs:CreateLogStream, logs:PutLogEvents, and SNS publish permissions. Create event target linking the rule to Lambda function. Set up CloudWatch dashboard for monitoring refresh execution metrics.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Create deployment scripts and test end-to-end refresh system",
            "description": "Develop AWS CLI deployment scripts and comprehensive testing suite for the scheduled refresh infrastructure",
            "dependencies": [
              "10.5",
              "10.6"
            ],
            "details": "Create shell script with AWS CLI commands to deploy Lambda function, create CloudWatch Events rule, and set up IAM roles. Include commands to create/update all 10 materialized views without AUTO REFRESH. Develop test script to validate Lambda execution, verify all views refresh successfully, check refresh timestamps, and validate row counts. Create rollback script for emergency scenarios. Document deployment process and create runbook for operations team.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 11,
        "title": "Refactor all Glue jobs to work with Apache Iceberg",
        "description": "Update all AWS Glue ETL jobs to use Apache Iceberg format following the HMUPatient.py template",
        "details": "Refactor all AWS Glue ETL jobs to work with Apache Iceberg format, following the pattern established in HMUPatient/HMUPatient.py. Each job needs to be updated to: \n1) Read from S3 using Iceberg catalog instead of Glue Catalog\n2) Configure Spark session with Iceberg extensions\n3) Use the correct S3 bucket paths and database names for the Iceberg tables\n4) Set logging level to DEBUG for better troubleshooting\n5) Update table read operations to use spark.table() with fully qualified Iceberg table names\n6) Review and ensure naming consistency across all jobs for aliased fields and new fields\n   - Check for consistent snake_case vs camelCase usage\n   - Ensure similar transformations use the same field names across all jobs\n   - Verify consistent naming patterns for FHIR resource fields\n   - Standardize alias naming conventions for transformed columns\n   - Document any naming inconsistencies found and fix them\n7) Update shell scripts that manage Glue tasks to have the correct job names\n   - Update any deployment scripts (deploy_glue_jobs.sh, etc.)\n   - Update any monitoring or testing scripts\n   - Ensure job names in scripts match the actual Glue job names\n   - Update any batch processing or orchestration scripts\n8) Create a deployment script to recreate all Glue jobs from JSON configurations\n   - Create script to use AWS CLI to create Glue jobs from HMU*.json files\n   - All existing Glue jobs have been deleted and need to be recreated\n   - Script should iterate through all HMU*/HMU*.json files\n   - Use aws glue create-job command with proper parameters\n   - Include error handling and logging in the script\n\nThe JSON configuration files have already been updated. \n\nThe following Glue jobs need to be refactored and recreated:\n- HMUAllergyIntolerance\n- HMUCarePlan  \n- HMUCondition\n- HMUDiagnosticReport\n- HMUDocumentReference\n- HMUEncounter\n- HMUMedication\n- HMUMedicationDispense\n- HMUMedicationRequest\n- HMUObservation\n- HMUPatient\n- HMUPractitioner\n- HMUProcedure",
        "testStrategy": "Test each refactored Glue job by running it against sample data to ensure proper Iceberg catalog reading and Redshift writing functionality",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Refactor HMUAllergyIntolerance to use Iceberg",
            "description": "Update HMUAllergyIntolerance.py to use Iceberg catalog following HMUPatient.py template",
            "details": "Update the HMUAllergyIntolerance Glue job to use Iceberg catalog with DEBUG logging",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 2,
            "title": "Refactor HMUCarePlan to use Iceberg",
            "description": "Update HMUCarePlan.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 3,
            "title": "Refactor HMUCondition to use Iceberg",
            "description": "Update HMUCondition.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 4,
            "title": "Refactor HMUDiagnosticReport to use Iceberg",
            "description": "Update HMUDiagnosticReport.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 5,
            "title": "Refactor HMUDocumentReference to use Iceberg",
            "description": "Update HMUDocumentReference.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 6,
            "title": "Refactor HMUEncounter to use Iceberg",
            "description": "Update HMUEncounter.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 7,
            "title": "Refactor HMUMedication to use Iceberg",
            "description": "Update HMUMedication.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 8,
            "title": "Refactor HMUMedicationDispense to use Iceberg",
            "description": "Update HMUMedicationDispense.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 9,
            "title": "Refactor HMUMedicationRequest to use Iceberg",
            "description": "Update HMUMedicationRequest.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 10,
            "title": "Refactor HMUObservation to use Iceberg",
            "description": "Update HMUObservation.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 11,
            "title": "Refactor HMUPractitioner to use Iceberg",
            "description": "Update HMUPractitioner.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 12,
            "title": "Refactor HMUProcedure to use Iceberg",
            "description": "Update HMUProcedure.py to use Iceberg catalog following HMUPatient.py template",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 13,
            "title": "Update shell scripts with correct Glue job names",
            "description": "Find and update all shell scripts that reference Glue job names to ensure they match the actual job names",
            "details": "Search for all shell scripts (.sh files) in the project that reference Glue job names. Update any deployment, monitoring, testing, or orchestration scripts to use the correct job names (HMUAllergyIntolerance, HMUCarePlan, HMUCondition, etc.). Ensure consistency between scripts and actual AWS Glue job configurations.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 14,
            "title": "Create deployment script for Glue jobs",
            "description": "Create a shell script to deploy all Glue jobs using HMU*.json configuration files",
            "details": "Create deploy_glue_jobs.sh script that:\\n- Iterates through all HMU*/HMU*.json files\\n- Uses AWS CLI to create each Glue job (aws glue create-job --cli-input-json)\\n- Handles both creation and update scenarios (check if job exists first)\\n- Includes proper error handling and logging\\n- Sets correct AWS profile/region\\n- Since all jobs have been deleted, focus on creation first\\n- Should handle HMUPatient as well as the other 12 jobs",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          }
        ]
      },
      {
        "id": 12,
        "title": "Externalize table creation from Glue jobs to SQL DDL files",
        "description": "Extract table creation logic from each HMU_*.py job into individual SQL files stored in ./ddl directory (one file per table named table_name.sql). Each Glue job creates multiple tables, so there will be multiple SQL DDL files per job. For example, HMUPractitioner.py creates 4 tables: practitioners, practitioner_addresses, practitioner_names, and practitioner_telecoms.",
        "details": "Update Glue scripts to: 1) Check table existence during initialization, 2) Print columns from each table when initializing, 3) Assume tables exist in write_to_redshift function. The extraction should identify all CREATE TABLE statements in each Glue job and create separate SQL files for each table.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Extract DDL from HMUAllergyIntolerance.py",
            "description": "Extract table creation logic to ./ddl/allergy_intolerances.sql",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 2,
            "title": "Extract DDL from HMUCarePlan.py",
            "description": "Extract table creation logic to ./ddl/care_plans.sql",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 3,
            "title": "Extract DDL from HMUCondition.py",
            "description": "Extract table creation logic to ./ddl/conditions.sql and ./ddl/condition_*.sql files",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 4,
            "title": "Extract DDL from HMUDiagnosticReport.py",
            "description": "Extract table creation logic to ./ddl/diagnostic_reports.sql and related tables",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 5,
            "title": "Extract DDL from HMUDocumentReference.py",
            "description": "Extract table creation logic to ./ddl/document_references.sql",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 6,
            "title": "Extract DDL from HMUEncounter.py",
            "description": "Extract table creation logic to ./ddl/encounters.sql and related tables",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 7,
            "title": "Extract DDL from HMUMedication.py",
            "description": "Extract table creation logic to ./ddl/medications.sql",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 8,
            "title": "Extract DDL from HMUMedicationDispense.py",
            "description": "Extract table creation logic to ./ddl/medication_dispenses.sql",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 9,
            "title": "Extract DDL from HMUMedicationRequest.py",
            "description": "Extract table creation logic to ./ddl/medication_requests.sql",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 10,
            "title": "Extract DDL from HMUObservation.py",
            "description": "Extract table creation logic to ./ddl/observations.sql and observation_*.sql files",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 11,
            "title": "Extract DDL from HMUPatient.py",
            "description": "Extract table creation logic to ./ddl/patients.sql and related tables",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 12,
            "title": "Extract DDL from HMUPractitioner.py",
            "description": "Extract table creation logic to ./ddl/practitioners.sql",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 13,
            "title": "Extract DDL from HMUProcedure.py",
            "description": "Extract table creation logic to ./ddl/procedures.sql",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 14,
            "title": "Update Glue jobs to use external DDL",
            "description": "Modify all HMU*.py jobs to check table existence, print columns, and assume tables exist in write_to_redshift",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-09-10T00:22:35.036Z",
      "updated": "2025-10-08T23:13:36.101Z",
      "description": "Tasks for master context"
    }
  }
}